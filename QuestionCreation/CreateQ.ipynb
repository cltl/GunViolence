{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas\n",
    "from IPython.display import clear_output\n",
    "from datetime import datetime\n",
    "import json\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from classes import Question\n",
    "import classes\n",
    "import look_up_utils\n",
    "import createq_utils\n",
    "import pandas\n",
    "from display_utils import display_question"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set parameter values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pandas.read_pickle('../EventRegistries/GunViolenceArchive/frames/all')\n",
    "confusion_tuple = ('location', 'time')\n",
    "min_num_answer_incidents = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load frames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load look_up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "look_up, parameters2incident_uris = look_up_utils.create_look_up(df, \n",
    "                                                                 discard_ambiguous_names=True,\n",
    "                                                                 allowed_incident_years={2017},\n",
    "                                                                 check_name_in_article=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{('address', 'month'), ('city', 'day'), ('city', 'month'), ('city', 'year'), ('address', 'year'), ('state', 'day'), ('state', 'month'), ('state', 'year')}\n"
     ]
    }
   ],
   "source": [
    "candidates=createq_utils.lookup_and_merge(look_up, \n",
    "                                          parameters2incident_uris,\n",
    "                                          confusion_tuple,\n",
    "                                          min_num_answer_incidents,\n",
    "                                          df,\n",
    "                                          debug=False,\n",
    "                                          inspect_one=False,\n",
    "                                          set_attr_values=True) \n",
    "print({c.granularity for c in candidates})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Display a question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print('the available attributes are:\\n')\n",
    "for candidate in candidates:\n",
    "    for prop in dir(candidate):\n",
    "        if all([not prop.startswith('_'),\n",
    "                prop not in {'debug', 'confusion_df', 'answer_df'}]):\n",
    "            print(prop)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wanted_attrs = [\n",
    "    'q_id',\n",
    "    'question',\n",
    "    'granularity',\n",
    "    'answer_incident_uris',\n",
    "    'num_both_sf_overlap',\n",
    "    #'confusion_incident_uris',\n",
    "    'meanings',\n",
    "    'answer',\n",
    "    'c2s_ratio',\n",
    "    'location_confusion',\n",
    "    'time_confusion',\n",
    "    'participant_confusion',\n",
    "    'a_avg_num_sources',\n",
    "    'a_avg_date_spread',\n",
    "    'c_avg_num_sources',\n",
    "    'c_avg_date_spread',\n",
    "    'num_gvdb_part_annotations',\n",
    "    'loc_oa',\n",
    "    'time_oa'\n",
    "]\n",
    "\n",
    "#for candidate in candidates:\n",
    " #   clear_output()\n",
    " #   display_question(candidate, wanted_attrs)\n",
    " #   break\n",
    "    #input('next?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "rm -rf trial\n",
    "mkdir trial\n",
    "mkdir trial/system_input\n",
    "mkdir trial/system_output\n",
    "ls trial/\n",
    "cp ../Installing/setup.sh trial\n",
    "cp obtain_task_data.py trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "output_folder = 'trial'\n",
    "subtask = 'S2'\n",
    "event_types = ['killing', 'injuring']\n",
    "\n",
    "questions = dict()\n",
    "answers = dict()\n",
    "\n",
    "maximum = 100\n",
    "counter = 0\n",
    "for candidate in candidates:\n",
    "    \n",
    "    if 'address' in candidate.granularity:\n",
    "        continue \n",
    "        \n",
    "        \n",
    "    counter += 1\n",
    "    if counter == maximum:\n",
    "        break\n",
    "        \n",
    "        \n",
    "    dfs = [('gold', candidate.answer_df), \n",
    "           #('confusion', candidate.confusion_df)\n",
    "          ]\n",
    "    output_path = '%s/system_input/%s.conll' % (output_folder, candidate.q_id)\n",
    "    candidate.to_conll_one_file_per_question(dfs, output_path)\n",
    "    one_question = candidate.question(subtask, event_types)\n",
    "    \n",
    "    if len(candidate.all_doc_ids) != candidate.answer:\n",
    "        print('mismatch answer and incidents/documents')\n",
    "\n",
    "    if all([one_question is not None,\n",
    "            len(candidate.all_doc_ids) >= 2]):\n",
    "        questions[candidate.q_id] = one_question\n",
    "        answers[candidate.q_id] = {'numerical_answer': len(candidate.all_doc_ids),\n",
    "                                   'answer_docs' : candidate.all_doc_ids}\n",
    "\n",
    "question_out_path = '{output_folder}/questions.json'.format_map(locals())\n",
    "with open(question_out_path, 'w') as outfile:\n",
    "    outfile.write(json.dumps(questions, indent=4, sort_keys=True))\n",
    "    \n",
    "answers_out_path = '{output_folder}/answers.json'.format_map(locals())\n",
    "with open(answers_out_path, 'w') as outfile:\n",
    "    outfile.write(json.dumps(answers, indent=4, sort_keys=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
