{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas\n",
    "from collections import namedtuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('cache/mass_shootings_2015.pickle', 'rb') as infile:\n",
    "    look_up = pickle.load(infile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_dataframe():\n",
    "    df_paths = [#'frames/mass_shootings_2013',\n",
    "                #'frames/mass_shootings_2014',\n",
    "                '../EventRegistries/GunViolence/frames/mass_shootings_2015']\n",
    "    frames = []\n",
    "    for df_path in df_paths:\n",
    "        with open(df_path, 'rb') as infile:\n",
    "            df = pickle.load(infile)\n",
    "            frames.append(df)\n",
    "    df = pandas.concat(frames)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df=create_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys([('location',), ('participant',), ('location', 'participant')])\n"
     ]
    }
   ],
   "source": [
    "print(look_up.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "CONFUSION_TUPLE=('location', 'participant')\n",
    "MIN_CONFUSION=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('city', 'full_name')\n",
      "('city', 'last')\n",
      "('city', 'last')\n",
      "('city', 'last')\n",
      "('city', 'first')\n",
      "('city', 'first')\n",
      "('city', 'first')\n",
      "('city', 'first')\n"
     ]
    }
   ],
   "source": [
    "def lookup_and_merge(look_up, confusion_key):\n",
    "    nice_combos=[]\n",
    "    Candidate=namedtuple('Candidate', 'granularity sf meanings num_answer_e incidents')\n",
    "    for granularity in (look_up[confusion_key]):\n",
    "        if granularity[0]=='state':\n",
    "            continue\n",
    "        for sf in look_up[confusion_key][granularity]:\n",
    "            len_combo=len(look_up[confusion_key][granularity][sf])\n",
    "            meanings=look_up[confusion_key][granularity][sf]\n",
    "            incidents=set()\n",
    "            for m in meanings:\n",
    "                incidents.add(m[1][0])\n",
    "            if(len_combo>MIN_CONFUSION):\n",
    "                c=Candidate(granularity=granularity, sf=sf, meanings=meanings, num_answer_e=len_combo, incidents=incidents)\n",
    "                nice_combos.append(c)\n",
    "    return nice_combos\n",
    "\n",
    "candidates=lookup_and_merge(look_up, CONFUSION_TUPLE)\n",
    "for c in candidates:\n",
    "    print(c.granularity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def compute_num_docs(include, df):\n",
    "#    include=('454788', '419250')\n",
    "    results=df.query('incident_uri in @include')\n",
    "    s=0\n",
    "    print(include)\n",
    "    for index, row in results.iterrows():\n",
    "        s+=len(row['incident_sources'])\n",
    "    avg=s/len(include)\n",
    "    print(\"Average number of documents per incident: %f\" % avg)\n",
    "    return avg\n",
    "\n",
    "#compute_num_docs(('454788', '419250'), df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CANDIDATE: ('Daytona Beach', 'Rakim Watson')\n",
      "The location Daytona Beach has 1 meanings over 3 incidents. OA is 1, Noise-to-Signal ratio is 1.500000\n",
      "The participant Rakim Watson has 0 meanings over 0 incidents. OA is 0, Noise-to-Signal ratio is 0.000000\n",
      "{'317165', '588835'}\n",
      "Average number of documents per incident: 1.500000\n",
      "Question score: 0.800000\n",
      "\n",
      "Q: How many killing events that involve Rakim Watson happened in Daytona Beach?\n",
      "A: 2\n",
      "###########################################################################\n",
      "\n",
      "CANDIDATE: ('Daytona Beach', 'Watson')\n",
      "The location Daytona Beach has 1 meanings over 3 incidents. OA is 1, Noise-to-Signal ratio is 1.500000\n",
      "The participant Watson has 2 meanings over 2 incidents. OA is 2, Noise-to-Signal ratio is 1.000000\n",
      "{'317165', '588835'}\n",
      "Average number of documents per incident: 1.500000\n",
      "Question score: 1.400000\n",
      "\n",
      "Q: How many killing events that involve Watson happened in Daytona Beach?\n",
      "A: 2\n",
      "###########################################################################\n",
      "\n",
      "CANDIDATE: ('Rochester', 'Williams')\n",
      "The location Rochester has 1 meanings over 3 incidents. OA is 1, Noise-to-Signal ratio is 1.500000\n",
      "The participant Williams has 12 meanings over 12 incidents. OA is 12, Noise-to-Signal ratio is 6.000000\n",
      "{'398361', '412487'}\n",
      "Average number of documents per incident: 7.000000\n",
      "Question score: 5.500000\n",
      "\n",
      "Q: How many killing events that involve Williams happened in Rochester?\n",
      "A: 2\n",
      "###########################################################################\n",
      "\n",
      "CANDIDATE: ('Savannah', 'Washington')\n",
      "The location Savannah has 1 meanings over 4 incidents. OA is 1, Noise-to-Signal ratio is 2.000000\n",
      "The participant Washington has 4 meanings over 4 incidents. OA is 4, Noise-to-Signal ratio is 2.000000\n",
      "{'464002', '457037'}\n",
      "Average number of documents per incident: 1.500000\n",
      "Question score: 2.100000\n",
      "\n",
      "Q: How many killing events that involve Washington happened in Savannah?\n",
      "A: 2\n",
      "###########################################################################\n",
      "\n",
      "CANDIDATE: ('Clarksville', 'Timothy')\n",
      "The location Clarksville has 1 meanings over 2 incidents. OA is 1, Noise-to-Signal ratio is 1.000000\n",
      "The participant Timothy has 4 meanings over 4 incidents. OA is 4, Noise-to-Signal ratio is 2.000000\n",
      "{'311922', '281663'}\n",
      "Average number of documents per incident: 1.500000\n",
      "Question score: 1.900000\n",
      "\n",
      "Q: How many killing events that involve Timothy happened in Clarksville?\n",
      "A: 2\n",
      "###########################################################################\n",
      "\n",
      "CANDIDATE: ('Cleveland', 'Michael')\n",
      "The location Cleveland has 1 meanings over 4 incidents. OA is 1, Noise-to-Signal ratio is 2.000000\n",
      "The participant Michael has 12 meanings over 12 incidents. OA is 12, Noise-to-Signal ratio is 6.000000\n",
      "{'337855', '370187'}\n",
      "Average number of documents per incident: 4.000000\n",
      "Question score: 5.000000\n",
      "\n",
      "Q: How many killing events that involve Michael happened in Cleveland?\n",
      "A: 2\n",
      "###########################################################################\n",
      "\n",
      "CANDIDATE: ('Daytona Beach', 'Rakim')\n",
      "The location Daytona Beach has 1 meanings over 3 incidents. OA is 1, Noise-to-Signal ratio is 1.500000\n",
      "The participant Rakim has 2 meanings over 2 incidents. OA is 2, Noise-to-Signal ratio is 1.000000\n",
      "{'317165', '588835'}\n",
      "Average number of documents per incident: 1.500000\n",
      "Question score: 1.400000\n",
      "\n",
      "Q: How many killing events that involve Rakim happened in Daytona Beach?\n",
      "A: 2\n",
      "###########################################################################\n",
      "\n",
      "CANDIDATE: ('Brooklyn', 'Ronald')\n",
      "The location Brooklyn has 1 meanings over 5 incidents. OA is 1, Noise-to-Signal ratio is 2.500000\n",
      "The participant Ronald has 6 meanings over 6 incidents. OA is 6, Noise-to-Signal ratio is 3.000000\n",
      "{'330611', '387194'}\n",
      "Average number of documents per incident: 4.000000\n",
      "Question score: 3.300000\n",
      "\n",
      "Q: How many killing events that involve Ronald happened in Brooklyn?\n",
      "A: 2\n",
      "###########################################################################\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def compute_metrics(c, look_up, confusion_key, index):\n",
    "    my_set=set()\n",
    "    confusion=confusion_key[index]\n",
    "    meanings=look_up[(confusion,)][c.granularity[index]][c.sf[index]]\n",
    "    for m in meanings.values():\n",
    "        for incident in m:\n",
    "            my_set.add(incident)\n",
    "#    print(c.sf[index], my_set)\n",
    "    num_noisy_e=len(my_set)\n",
    "    ns_ratio=num_noisy_e/c.num_answer_e\n",
    "    oa=len(meanings)\n",
    "    print('The %s %s has %d meanings over %d incidents. OA is %d, Noise-to-Signal ratio is %f' % (confusion, c.sf[index],oa,num_noisy_e, oa, ns_ratio))\n",
    "    return ns_ratio, oa\n",
    "\n",
    "\n",
    "            \n",
    "    \n",
    "def compute_confusion_metrics(look_up, confusion_key, candidates, df):\n",
    "    for c in candidates:\n",
    "        print('CANDIDATE: %s' % str(c.sf))\n",
    "        ns_loc, oa_loc=compute_metrics(c, look_up, confusion_key, 0)\n",
    "        ns_part, oa_part=compute_metrics(c, look_up, confusion_key, 1)\n",
    "        avg_num_docs=compute_num_docs(c.incidents, df)\n",
    "        score=(ns_loc + oa_loc + ns_part + oa_part+avg_num_docs)/5\n",
    "        print(\"Question score: %f\" % score)\n",
    "        print()\n",
    "        print(\"Q: How many killing events that involve %s happened in %s?\" % (c.sf[1], c.sf[0]))\n",
    "        print(\"A: %d\" % c.num_answer_e)\n",
    "        print(\"###########################################################################\")\n",
    "        print()\n",
    "        \n",
    "\n",
    "compute_confusion_metrics(look_up,CONFUSION_TUPLE,candidates, df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['Rakim Watson'])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# debug rakim watson\n",
    "look_up[('participant',)]['full_name'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
