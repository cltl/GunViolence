{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from lxml import etree\n",
    "import pickle\n",
    "import pandas\n",
    "from datetime import datetime\n",
    "import csv\n",
    "import json\n",
    "from newspaper import Article\n",
    "from dateutil import parser\n",
    "from collections import Counter\n",
    "\n",
    "import utils\n",
    "import classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# File mappings\n",
    "DIRECTORY='GVDB/gvdb-aggregated-db'\n",
    "article_info=\"%s/Articles-with-extracted-info.tsv\" % DIRECTORY\n",
    "\n",
    "def get_gvdb_sources():\n",
    "    with open(article_info, 'r') as csvfile:\n",
    "        spamreader = csv.reader(csvfile, delimiter='\\t', quotechar='\"')\n",
    "        gvdb_sources={}\n",
    "        for index,row in enumerate(spamreader):\n",
    "            if row[0]=='Article url':\n",
    "                continue\n",
    "            url=row[0]\n",
    "            ann=json.loads(row[3])\n",
    "            gvdb_sources[url]=ann\n",
    "        return gvdb_sources\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gvdb_sources=get_gvdb_sources()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_gvdb_annotations(gva_sources):\n",
    "    annotations={}\n",
    "    for gva_src in gva_sources:\n",
    "        if gva_src in gvdb_sources:\n",
    "            annotations[gva_src]=gvdb_sources[gva_src]\n",
    "    return annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_cached_dct_api(url):\n",
    "    hashed_url=utils.hash_uri(url)\n",
    "    if hashed_url in dates_api and dates_api[hashed_url]!='NODATE':\n",
    "        return datetime.strptime(dates_api[hashed_url], '%a, %d %b %Y %H:%M:%S GMT').date()\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def get_cached_dct_gvdb(url):\n",
    "    if url in dates_gvdb and dates_gvdb[url]:\n",
    "        return dates_gvdb[url]\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_archive_uri(original_url):\n",
    "    if not original_url:\n",
    "        return None\n",
    "    if not utils.is_archive_uri(original_url):\n",
    "        url=utils.generate_archive_uri(original_url)\n",
    "        if not url:\n",
    "            utils.log_no_archive(original_url)\n",
    "        return url\n",
    "    else:\n",
    "        return original_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def validate_date(d):\n",
    "    return d and d.year>=2013 and d.year<=2017"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def website_extraction(original_url, url, max_sec=10, debug=False):\n",
    "    if not url:\n",
    "        return classes.NewsItem(\n",
    "            title='',\n",
    "            content='',\n",
    "            dct=None,\n",
    "            id=None,\n",
    "            uri=''\n",
    "        )\n",
    "    language='en'\n",
    "    a=Article(url, language)\n",
    "    a.download()\n",
    "    attempts = 0\n",
    "\n",
    "    while not a.is_downloaded:\n",
    "        time.sleep(1)\n",
    "        attempts += 1\n",
    "\n",
    "        if attempts == max_sec:\n",
    "            print(\"Extraction error with the article %s\" % url)\n",
    "            return classes.NewsItem(\n",
    "                title='',\n",
    "                content='',\n",
    "                dct=None,\n",
    "                id=None,\n",
    "                uri=''\n",
    "            )\n",
    "\n",
    "    a.parse()\n",
    "    title=a.title\n",
    "    content=a.text\n",
    "    dct_newspaper=None\n",
    "    dct_cached_api=None\n",
    "    dct_cached_gvdb=None\n",
    "    dct_newspaper=a.publish_date or a.meta_data['date'] or a.meta_data['published_time']\n",
    "    if a.publish_date:\n",
    "        if validate_date(a.publish_date.date()):\n",
    "            dct_newspaper=a.publish_date.date()\n",
    "    elif a.meta_data['date']:\n",
    "        if validate_date(parser.parse(a.meta_data['date']).date()):\n",
    "            dct_newspaper=parser.parse(a.meta_data['date']).date()\n",
    "    elif a.meta_data['published_time']:\n",
    "        if validate_date(a.meta_data['published_time'].date()):\n",
    "            dct_newspaper=a.meta_data['published_time'].date()\n",
    "    if validate_date(get_cached_dct_api(original_url)):\n",
    "        dct_cached_api=get_cached_dct_api(original_url)\n",
    "    if validate_date(get_cached_dct_gvdb(original_url)):\n",
    "        dct_cached_gvdb=get_cached_dct_gvdb(original_url)\n",
    "\n",
    "    dct=dct_cached_api or dct_cached_gvdb or dct_newspaper\n",
    "    if not dct:\n",
    "        utils.log_no_date(url)\n",
    "        return classes.NewsItem(\n",
    "            title='',\n",
    "            content='',\n",
    "            dct=None,\n",
    "            id=None,\n",
    "            uri=''\n",
    "        )\n",
    "    else:\n",
    "        diff_date=False\n",
    "        for date_option in [dct_cached_api,dct_cached_gvdb,dct_newspaper]:\n",
    "            if date_option and date_option!=dct:\n",
    "                diff_date=True\n",
    "                break\n",
    "        if diff_date:\n",
    "            return classes.NewsItem(\n",
    "                title='',\n",
    "                content='',\n",
    "                dct=None,\n",
    "                id=None,\n",
    "                uri=''\n",
    "            )\n",
    "        else:\n",
    "            return classes.NewsItem(\n",
    "                title=title,\n",
    "                content=content,\n",
    "                dct=dct,\n",
    "                id=utils.hash_uri(url),\n",
    "                uri=url\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_gunviolence_page(url):\n",
    "    \"\"\"\n",
    "    create pandas.dataframe from one page of gunviolence e.g.\n",
    "    http://www.gunviolencearchive.org/reports/mass-shootings/2014\n",
    "    \n",
    "    :param str url: gunviolence output page\n",
    "    http://www.gunviolencearchive.org/reports/mass-shootings/2014\n",
    "    \n",
    "    :rtype: pandas.core.frame.DataFrame\n",
    "    :return: info from the violence page in a dataframe\n",
    "    \n",
    "    \"\"\"\n",
    "    call = requests.get(url)\n",
    "    doc = etree.HTML(call.text)\n",
    "    \n",
    "    headers = ['incident_uri',\n",
    "               'date', 'state', 'city_or_county',\n",
    "               'address', 'num_killed', 'num_injured',\n",
    "               'incident_url', 'incident_sources',\n",
    "               'participants', 'gvdb_annotation']\n",
    "    list_of_reports = []\n",
    "\n",
    "    for tr_el in doc.xpath('//tr[@class=\"even\" or @class=\"odd\"]'):\n",
    "        td_els = tr_el.getchildren()\n",
    "\n",
    "        date = td_els[0].text\n",
    "        state = td_els[1].text\n",
    "        city_or_county = td_els[2].text\n",
    "        address = td_els[3].text\n",
    "        num_killed = int(td_els[4].text)\n",
    "        num_injured = int(td_els[5].text)\n",
    "\n",
    "        operations_el = td_els[6]\n",
    "        a_els = operations_el.findall('ul/li/a')\n",
    "\n",
    "        # get incident url\n",
    "        incident_base = 'http://www.gunviolencearchive.org'\n",
    "        incident_ending = a_els[0].get('href')\n",
    "        incident_url = incident_base + incident_ending\n",
    "        incident_uri = incident_url.split('/')[-1]\n",
    "\n",
    "        # get source url\n",
    "        source_url = ''\n",
    "        if len(a_els) == 2:\n",
    "            source_url = a_els[1].get('href')\n",
    "\n",
    "        # get incident sources\n",
    "        incident_call = requests.get(incident_url)\n",
    "        incident_doc = etree.HTML(incident_call.text)\n",
    "\n",
    "        incident_sources = set()\n",
    "        for li_el in incident_doc.xpath('//li'):\n",
    "            if li_el.text is not None:\n",
    "                if 'URL:' in li_el.text:\n",
    "                    for a_el in li_el.xpath('a'):\n",
    "                        incident_sources.add(a_el.get('href'))\n",
    "                        \n",
    "        # get participants information\n",
    "        div_els = incident_doc.xpath('//div[h2[text()=\"Participants\"]]')\n",
    "        div_el = div_els[0]\n",
    "        participants = []\n",
    "\n",
    "        for ul_el in div_el.iterfind('div/ul'):\n",
    "            participant = dict()\n",
    "            for li_el in ul_el.iterfind('li'):\n",
    "                attr, value = li_el.text.split(':')\n",
    "                participant[attr] = value\n",
    "            participants.append(participant)\n",
    "            \n",
    "            \n",
    "        # Cleanup the directory\n",
    "        my_dir=utils.reset_dir(incident_url)\n",
    "            \n",
    "        # gather news sources\n",
    "        sources=set()\n",
    "        sources.add(source_url)\n",
    "        sources.update(incident_sources)\n",
    "        \n",
    "        # extract sources data\n",
    "        ready_sources={}\n",
    "        for src in sources:\n",
    "            archive_src=get_archive_uri(src)\n",
    "            if archive_src:\n",
    "                article=website_extraction(src, archive_src)\n",
    "                if article and article.id and article.dct:\n",
    "                    target_file=\"%s%s.json\" % (my_dir, article.id)\n",
    "                    article.toJSON(target_file)\n",
    "                    print(\"Article %s written!\" % article.uri)\n",
    "                    ready_sources[archive_src]=article.dct\n",
    "                else:\n",
    "                    errors.write(src + '\\n')\n",
    "        \n",
    "        if len(ready_sources):\n",
    "            annotations=get_gvdb_annotations(sources)\n",
    "\n",
    "            incident_report = [incident_uri,\n",
    "                               date, state, city_or_county,\n",
    "                               address, num_killed, num_injured,\n",
    "                               incident_url, ready_sources, \n",
    "                               participants, annotations]\n",
    "            list_of_reports.append(incident_report)\n",
    "    \n",
    "    df = pandas.DataFrame(list_of_reports, columns=headers)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def paginate(base_url, debug=False):\n",
    "    \"\"\"\n",
    "    paginate over gunviolence urls\n",
    "    \n",
    "    :param str base_url: paginate over gunviolence urls\n",
    "    \n",
    "    :rtype: pandas.core.frame.DataFrame\n",
    "    :return: all results from one category\n",
    "    \n",
    "    \"\"\"\n",
    "    frames = []\n",
    "    previous_df = get_gunviolence_page(base_url)\n",
    "    frames.append(previous_df)\n",
    "\n",
    "    keep_going = True\n",
    "    counter = 1\n",
    "    while keep_going:\n",
    "        url = base_url + '?page=' + str(counter)\n",
    "        print(url)\n",
    "        \n",
    "        df = get_gunviolence_page(url)\n",
    "        counter += 1\n",
    "\n",
    "        if df.equals(previous_df):\n",
    "            keep_going = False\n",
    "        else:\n",
    "            frames.append(df)\n",
    "            previous_df = df\n",
    "\n",
    "    df = pandas.concat(frames)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DATES_CACHE='date_cache.p'\n",
    "GVDB_DATES_CACHE='gvdb_date_cache.p'\n",
    "ERRORS_FILE=\"logs/errors.txt\"\n",
    "errors=open(ERRORS_FILE, \"a+\")\n",
    "\n",
    "dates_api=pickle.load(open(DATES_CACHE, 'rb'))\n",
    "dates_gvdb=pickle.load(open(GVDB_DATES_CACHE, 'rb'))\n",
    "\n",
    "utils.reset_files()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "starting frames/mass_shootings_2015 2017-03-19 18:30:47.540881\n",
      "No archive version for http://www.nola.com/crime/index.ssf/2016/03/suspect_arrested_in_new_years.html#incart_river_index\n",
      "Article http://web.archive.org/web/20160206223803/http://www.wwltv.com:80/story/news/crime/2016/01/01/new-years-eve-shooting-raises-questions-city-crime/78190114/ written!\n",
      "Article http://web.archive.org/web/20160408212600/http://www.wbbjtv.com:80/video/four-injured-in-bar-shooting/ written!\n",
      "Article http://web.archive.org/web/20160229042538/http://www.philly.com:80/philly/news/Four_injured_in_Feltonville_shooting.html written!\n"
     ]
    }
   ],
   "source": [
    "urls_and_paths = [('frames/children_killed', 'http://www.gunviolencearchive.org/children-killed'),\n",
    "                  ('frames/children_injured', 'http://www.gunviolencearchive.org/children-injured'),\n",
    "                  ('frames/teens_killed', 'http://www.gunviolencearchive.org/teens-killed'),\n",
    "                  ('frames/teens_injured', 'http://www.gunviolencearchive.org/teens-injured'),\n",
    "                  ('frames/accidental_deaths', 'http://www.gunviolencearchive.org/accidental-deaths'),\n",
    "                  ('frames/accidental_injuries', 'http://www.gunviolencearchive.org/accidental-injuries'),\n",
    "                  ('frames/accidental_deaths_children', 'http://www.gunviolencearchive.org/accidental-child-deaths'),\n",
    "                  ('frames/accidental_injuries_children', 'http://www.gunviolencearchive.org/accidental-child-injuries'),\n",
    "                  ('frames/accidental_deaths_teens', 'http://www.gunviolencearchive.org/accidental-teen-deaths'),\n",
    "                  ('frames/accidental_injuries_teens', 'http://www.gunviolencearchive.org/accidental-teen-injuries'),\n",
    "                  ('frames/officer_involved_shootings', 'http://www.gunviolencearchive.org/officer-involved-shootings'),\n",
    "                  ('frames/mass_shootings_2013', 'http://www.gunviolencearchive.org/reports/mass-shootings/2013'),\n",
    "                  ('frames/mass_shootings_2014', 'http://www.gunviolencearchive.org/reports/mass-shootings/2014'),\n",
    "                  ('frames/mass_shootings_2015', 'http://www.gunviolencearchive.org/reports/mass-shootings/2015'),\n",
    "                  ('frames/mass_shootings', 'http://www.gunviolencearchive.org/mass-shooting')\n",
    "                  ]\n",
    "\n",
    "urls_and_paths = [('frames/mass_shootings_2015', 'http://www.gunviolencearchive.org/reports/mass-shootings/2015')]\n",
    "for output_path, base_url in urls_and_paths:\n",
    "    print()\n",
    "    print('starting', output_path, datetime.now())\n",
    "    df = paginate(base_url)\n",
    "    with open(output_path, 'wb') as outfile:\n",
    "        pickle.dump(df, outfile)\n",
    "    print('done', output_path, datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for index, row in df.iterrows():\n",
    "    print(len(row['gvdb_annotation']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
