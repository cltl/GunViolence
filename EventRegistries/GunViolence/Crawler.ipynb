{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from lxml import etree\n",
    "import pickle\n",
    "import pandas\n",
    "from datetime import datetime\n",
    "import csv\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# File mappings\n",
    "DIRECTORY='GVDB/gvdb-aggregated-db'\n",
    "article_info=\"%s/Articles-with-extracted-info.tsv\" % DIRECTORY\n",
    "\n",
    "def get_gvdb_sources():\n",
    "    with open(article_info, 'r') as csvfile:\n",
    "        spamreader = csv.reader(csvfile, delimiter='\\t', quotechar='\"')\n",
    "        gvdb_sources={}\n",
    "        for index,row in enumerate(spamreader):\n",
    "            if row[0]=='Article url':\n",
    "                continue\n",
    "            url=row[0]\n",
    "            ann=json.loads(row[3])\n",
    "            gvdb_sources[url]=ann\n",
    "        return gvdb_sources\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gvdb_sources=get_gvdb_sources()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_gvdb_annotations(gva_sources):\n",
    "    annotations={}\n",
    "    for gva_src in gva_sources:\n",
    "        if gva_src in gvdb_sources:\n",
    "            annotations[gva_src]=gvdb_sources[gva_src]\n",
    "    return annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_gunviolence_page(url):\n",
    "    \"\"\"\n",
    "    create pandas.dataframe from one page of gunviolence e.g.\n",
    "    http://www.gunviolencearchive.org/reports/mass-shootings/2014\n",
    "    \n",
    "    :param str url: gunviolence output page\n",
    "    http://www.gunviolencearchive.org/reports/mass-shootings/2014\n",
    "    \n",
    "    :rtype: pandas.core.frame.DataFrame\n",
    "    :return: info from the violence page in a dataframe\n",
    "    \n",
    "    \"\"\"\n",
    "    call = requests.get(url)\n",
    "    doc = etree.HTML(call.text)\n",
    "    \n",
    "    headers = ['incident_uri',\n",
    "               'date', 'state', 'city_or_county',\n",
    "               'address', 'num_killed', 'num_injured',\n",
    "               'incident_url', 'source_url', 'incident_sources',\n",
    "               'participants', 'gvdb_annotation']\n",
    "    list_of_reports = []\n",
    "\n",
    "    for tr_el in doc.xpath('//tr[@class=\"even\" or @class=\"odd\"]'):\n",
    "        td_els = tr_el.getchildren()\n",
    "\n",
    "        date = td_els[0].text\n",
    "        state = td_els[1].text\n",
    "        city_or_county = td_els[2].text\n",
    "        address = td_els[3].text\n",
    "        num_killed = int(td_els[4].text)\n",
    "        num_injured = int(td_els[5].text)\n",
    "\n",
    "        operations_el = td_els[6]\n",
    "        a_els = operations_el.findall('ul/li/a')\n",
    "\n",
    "        # get incident url\n",
    "        incident_base = 'http://www.gunviolencearchive.org'\n",
    "        incident_ending = a_els[0].get('href')\n",
    "        incident_url = incident_base + incident_ending\n",
    "        incident_uri = incident_url.split('/')[-1]\n",
    "\n",
    "        # get source url\n",
    "        source_url = ''\n",
    "        if len(a_els) == 2:\n",
    "            source_url = a_els[1].get('href')\n",
    "\n",
    "        # get incident sources\n",
    "        incident_call = requests.get(incident_url)\n",
    "        incident_doc = etree.HTML(incident_call.text)\n",
    "\n",
    "        incident_sources = set()\n",
    "        for li_el in incident_doc.xpath('//li'):\n",
    "            if li_el.text is not None:\n",
    "                if 'URL:' in li_el.text:\n",
    "                    for a_el in li_el.xpath('a'):\n",
    "                        incident_sources.add(a_el.get('href'))\n",
    "                        \n",
    "        # get participants information\n",
    "        div_els = incident_doc.xpath('//div[h2[text()=\"Participants\"]]')\n",
    "        div_el = div_els[0]\n",
    "        participants = []\n",
    "\n",
    "        for ul_el in div_el.iterfind('div/ul'):\n",
    "            participant = dict()\n",
    "            for li_el in ul_el.iterfind('li'):\n",
    "                attr, value = li_el.text.split(':')\n",
    "                participant[attr] = value\n",
    "            participants.append(participant)\n",
    "            \n",
    "        sources=set()\n",
    "        sources.add(source_url)\n",
    "        sources.update(incident_sources)\n",
    "        \n",
    "        annotations=get_gvdb_annotations(sources)\n",
    "        \n",
    "        incident_report = [incident_uri,\n",
    "                           date, state, city_or_county,\n",
    "                           address, num_killed, num_injured,\n",
    "                           incident_url, source_url, incident_sources, \n",
    "                           participants, annotations]\n",
    "        list_of_reports.append(incident_report)\n",
    "    \n",
    "    df = pandas.DataFrame(list_of_reports, columns=headers)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def paginate(base_url, debug=False):\n",
    "    \"\"\"\n",
    "    paginate over gunviolence urls\n",
    "    \n",
    "    :param str base_url: paginate over gunviolence urls\n",
    "    \n",
    "    :rtype: pandas.core.frame.DataFrame\n",
    "    :return: all results from one category\n",
    "    \n",
    "    \"\"\"\n",
    "    frames = []\n",
    "    previous_df = get_gunviolence_page(base_url)\n",
    "    frames.append(previous_df)\n",
    "\n",
    "    keep_going = True\n",
    "    counter = 1\n",
    "    while keep_going:\n",
    "        url = base_url + '?page=' + str(counter)\n",
    "        print(url)\n",
    "        \n",
    "        df = get_gunviolence_page(url)\n",
    "        counter += 1\n",
    "\n",
    "        if df.equals(previous_df):\n",
    "            keep_going = False\n",
    "        else:\n",
    "            frames.append(df)\n",
    "            previous_df = df\n",
    "\n",
    "    df = pandas.concat(frames)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "starting frames/mass_shootings_2015 2017-03-14 15:48:12.149004\n",
      "http://www.gunviolencearchive.org/reports/mass-shootings/2015?page=1\n",
      "http://www.gunviolencearchive.org/reports/mass-shootings/2015?page=2\n",
      "http://www.gunviolencearchive.org/reports/mass-shootings/2015?page=3\n",
      "http://www.gunviolencearchive.org/reports/mass-shootings/2015?page=4\n",
      "http://www.gunviolencearchive.org/reports/mass-shootings/2015?page=5\n",
      "http://www.gunviolencearchive.org/reports/mass-shootings/2015?page=6\n",
      "http://www.gunviolencearchive.org/reports/mass-shootings/2015?page=7\n",
      "http://www.gunviolencearchive.org/reports/mass-shootings/2015?page=8\n",
      "http://www.gunviolencearchive.org/reports/mass-shootings/2015?page=9\n",
      "http://www.gunviolencearchive.org/reports/mass-shootings/2015?page=10\n",
      "http://www.gunviolencearchive.org/reports/mass-shootings/2015?page=11\n",
      "http://www.gunviolencearchive.org/reports/mass-shootings/2015?page=12\n",
      "http://www.gunviolencearchive.org/reports/mass-shootings/2015?page=13\n",
      "http://www.gunviolencearchive.org/reports/mass-shootings/2015?page=14\n",
      "done frames/mass_shootings_2015 2017-03-14 15:49:05.341062\n"
     ]
    }
   ],
   "source": [
    "urls_and_paths = [#('frames/children_killed', 'http://www.gunviolencearchive.org/children-killed'),\n",
    "                  #('frames/children_injured', 'http://www.gunviolencearchive.org/children-injured'),\n",
    "                  #('frames/teens_killed', 'http://www.gunviolencearchive.org/teens-killed'),\n",
    "                  #('frames/teens_injured', 'http://www.gunviolencearchive.org/teens-injured'),\n",
    "                  #('frames/accidental_deaths', 'http://www.gunviolencearchive.org/accidental-deaths'),\n",
    "                  #('frames/accidental_injuries', 'http://www.gunviolencearchive.org/accidental-injuries'),\n",
    "                  #('frames/accidental_deaths_children', 'http://www.gunviolencearchive.org/accidental-child-deaths'),\n",
    "                  #('frames/accidental_injuries_children', 'http://www.gunviolencearchive.org/accidental-child-injuries'),\n",
    "                  #('frames/accidental_deaths_teens', 'http://www.gunviolencearchive.org/accidental-teen-deaths'),\n",
    "                  #('frames/accidental_injuries_teens', 'http://www.gunviolencearchive.org/accidental-teen-injuries'),\n",
    "                  #('frames/officer_involved_shootings', 'http://www.gunviolencearchive.org/officer-involved-shootings'),\n",
    "                  #('frames/mass_shootings_2013', 'http://www.gunviolencearchive.org/reports/mass-shootings/2013'),\n",
    "                  #('frames/mass_shootings_2014', 'http://www.gunviolencearchive.org/reports/mass-shootings/2014'),\n",
    "                  ('frames/mass_shootings_2015', 'http://www.gunviolencearchive.org/reports/mass-shootings/2015'),\n",
    "                  #('frames/mass_shootings', 'http://www.gunviolencearchive.org/mass-shooting')\n",
    "                  ]\n",
    "for output_path, base_url in urls_and_paths:\n",
    "    print()\n",
    "    print('starting', output_path, datetime.now())\n",
    "    df = paginate(base_url)\n",
    "    with open(output_path, 'wb') as outfile:\n",
    "        pickle.dump(df, outfile)\n",
    "    print('done', output_path, datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "2\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "2\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "2\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "2\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "3\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "2\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "2\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "for index, row in df.iterrows():\n",
    "    print(len(row['gvdb_annotation']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
